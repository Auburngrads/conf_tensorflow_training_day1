---
title: "Session 1 Exercise: Abaolone as Regression"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

# Initialize package
library(keras)
library(tidyverse)
```

Follow the instructions in the instruction file to complete this exercise. The solution can be found in the solutions directory -- no peeking!

# Part 1: Data Preparation

## Obtain data

```{r data, warning = FALSE}

train_data <- read_csv("data/abalone_data.csv")
train_targets <- read_csv("data/abalone_labels_cont.csv")
train_targets <- train_targets$Rings

set.seed(136)
index <- sample(1:nrow(train_data), 0.2*nrow(train_data))

test_data <- train_data[index,]
test_targets <- train_targets[index]

train_data <- train_data[-index,]
train_targets <- train_targets[-index]

```

## Examine data:

Our predictor variables:

```{r strDataPre}
str(train_data)
str(test_data)
```

The target, response variable:

```{r strTargets}
str(train_targets)
```

## Prepare the data:

Convert z-scores:

```{r zScores, cache = T}
# parameters for Scaling:
mean <- colMeans(train_data) # mean of each column
std <- apply(train_data, 2, sd) # stdev of each column

# Calculate feature-wise (within-variable) z-scores: (x - mean)/std
train_data <- scale(train_data, center = mean, scale = std)
test_data <- scale(test_data, center = mean, scale = std)
```

# Part 2: Define Network

Define

```{r}
network <- keras_model_sequential() %>% 
  layer_dense(units = 64, activation = "relu", input_shape = 8) %>% 
  layer_dense(units = 64, activation = "relu") %>% 
  layer_dense(units = 1) 

```

Compile

```{r}
network %>% compile(
  optimizer = "rmsprop", 
  loss = "mse", 
  metrics = "mae"
)

```

Train (`fit()`)

```{r runZ, echo = F, results = 'hide', cache = T}
# Train it on the entirety of the data.
history <- network %>% 
  fit(
    train_data, 
    train_targets,
    epochs = 80, 
    batch_size = 16, 
    verbose = TRUE
  )

```

```{r}
plot(history)

```


## Results

```{r resultsZ}
result <- network %>% evaluate(test_data, test_targets)
result
```

Our predictions are off by about `r result$mean_absolute_error` Rings.